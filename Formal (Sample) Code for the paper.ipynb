{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2f4ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import pydotplus\n",
    "import warnings\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.inspection import PartialDependenceDisplay, partial_dependence, permutation_importance\n",
    "import mpl_toolkits.mplot3d\n",
    "import matplotlib.ticker as mtick\n",
    "import shap\n",
    "from PyALE import ale\n",
    "\n",
    "# 显示DateFrame所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "plt.rcParams['xtick.direction'] = 'in'  #将x周的刻度线方向设置向内\n",
    "plt.rcParams['ytick.direction'] = 'in'  #将y轴的刻度方向设置向内\n",
    "\n",
    "# plt.rcParams['font.sans-serif']= ['Songti SC']  #防止中文乱码\n",
    "plt.rcParams['font.sans-serif']= ['Times new Roman']\n",
    "\n",
    "#显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = True\n",
    "\n",
    "# 忽略user warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# RF随机数\n",
    "random_seed = 0\n",
    "\n",
    "# 文件路径\n",
    "# data_path = ''  # 数据存储路径\n",
    "\n",
    "# 数据读取与处理\n",
    "# df = pd.DataFrame(pd.read_excel(data_path, header=0))\n",
    "\n",
    "# 描述性统计结果\n",
    "# des_table = round(df.describe(), 6)\n",
    "\n",
    "# 数据选取 \n",
    "# data = df.iloc[:, np.r_[1, 2, 6:15]]\n",
    "\n",
    "# 绘制皮尔逊相关系数矩阵热力图\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# corr_df = data.corr()\n",
    "# sns.heatmap(corr_df, cmap=\"binary\", annot=True, vmax=1, square=True, fmt=\".3f\", linewidth=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd71b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF_Regression_Model(object):\n",
    "\n",
    "    def __init__(self, XTrain, yTrain, XTest, yTest, data):\n",
    "        self.X_train = XTrain\n",
    "        self.y_train = yTrain\n",
    "        self.X_test = XTest\n",
    "        self.y_test = yTest\n",
    "        self.data = data\n",
    "        self.seed = random_seed\n",
    "        self.NJobs = 6\n",
    "        self.cv = 3\n",
    "        self.n_estimators_range = [int(x) for x in np.linspace(400, 1500, 50)]\n",
    "        self.__max_features_range = ['sqrt', 'log2']\n",
    "        self.__max_depth_range = [int(x) for x in np.linspace(10, 100, 10)]\n",
    "        self.__min_samples_split_range = [2, 5, 10]\n",
    "        self.__min_samples_leaf_range = [1, 2, 4, 8]\n",
    "        path = DecisionTreeRegressor(random_state=self.seed).cost_complexity_pruning_path(X_train, y_train)\n",
    "        self.__ccp_alphas = list(path.ccp_alphas)\n",
    "        self.scoring = {'neg_mse':'neg_mean_squared_error',\n",
    "                        'neg_mae':'neg_mean_absolute_error',\n",
    "                        'r2':'r2'}\n",
    "        self.__criterion = 'squared_error'\n",
    "        self.best_RF_model = None\n",
    "        self.y_pred = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.best_RF_model\n",
    "\n",
    "    def search_hp_fit(self):\n",
    "        # 随机搜索选取最优超参数-RandomSearch\n",
    "        random_forest_hp_range = {'n_estimators': self.n_estimators_range,\n",
    "                                  'max_features': self.__max_features_range,\n",
    "                                  'max_depth': self.__max_depth_range,\n",
    "                                  'min_samples_split': self.__min_samples_split_range,\n",
    "                                  'min_samples_leaf': self.__min_samples_leaf_range,\n",
    "                                  'ccp_alpha':self.__ccp_alphas[0:len(self.__ccp_alphas):50]\n",
    "                                  }\n",
    "\n",
    "        RF_test_base = RandomForestRegressor(criterion=self.__criterion,\n",
    "                                             random_state=self.seed)\n",
    "\n",
    "        RF_test_random = RandomizedSearchCV(estimator=RF_test_base,\n",
    "                                            param_distributions=random_forest_hp_range,\n",
    "                                            n_iter=200,\n",
    "                                            n_jobs=self.NJobs,\n",
    "                                            cv=KFold(n_splits=self.cv, shuffle=True,\n",
    "                                                     random_state=self.seed),\n",
    "                                            random_state=self.seed,\n",
    "                                            scoring=self.scoring,\n",
    "                                            refit='neg_mse'\n",
    "                                            )\n",
    "        RF_test_random.fit(self.X_train, self.y_train)\n",
    "        best_hp_Random = RF_test_random.best_params_\n",
    "        best_hp_dict = best_hp_Random\n",
    "\n",
    "        # GridSearchCV精准搜索寻找最优超参数：缩小超参数范围，确定最优超参数\n",
    "        dict_n_estimators = best_hp_dict['n_estimators']\n",
    "        dict_min_samples_split = best_hp_dict['min_samples_split']\n",
    "        dict_min_samples_leaf = best_hp_dict['min_samples_leaf']\n",
    "        dict_max_depth = best_hp_dict['max_depth']\n",
    "        dict_max_features = best_hp_dict['max_features']\n",
    "        dict_ccp_alpha = best_hp_dict['ccp_alpha']\n",
    "\n",
    "        best_hp_dict['n_estimators'] = list(set([\n",
    "            int(x) for x in range(dict_n_estimators - math.ceil(dict_n_estimators / 10),\n",
    "                                  dict_n_estimators + math.ceil(dict_n_estimators / 10),\n",
    "                                  5)\n",
    "        ]))\n",
    "\n",
    "        best_hp_dict['min_samples_split'] = list(set([\n",
    "            int(x) for x in range(\n",
    "                dict_min_samples_split - math.ceil(dict_min_samples_split / 4),\n",
    "                dict_min_samples_split + math.ceil(dict_min_samples_split / 4) + 1,\n",
    "                1)\n",
    "        ]))\n",
    "\n",
    "        # min_samples_split 必须大于1\n",
    "        for k in range(0, len(best_hp_dict.get('min_samples_split'))):\n",
    "            if best_hp_dict.get('min_samples_split')[k] <= 1:\n",
    "                best_hp_dict.get('min_samples_split')[k] = 2\n",
    "\n",
    "        best_hp_dict['min_samples_leaf'] = list(set([\n",
    "            int(x) for x in range(\n",
    "                dict_min_samples_leaf - math.ceil(dict_min_samples_leaf / 4),\n",
    "                dict_min_samples_leaf + math.ceil(dict_min_samples_leaf / 4) + 1,\n",
    "                1)\n",
    "        ]))\n",
    "\n",
    "        # min_samples_leaf 必须大于1\n",
    "        for k in range(0, len(best_hp_dict.get('min_samples_leaf'))):\n",
    "            if best_hp_dict.get('min_samples_leaf')[k] <= 1:\n",
    "                best_hp_dict.get('min_samples_leaf')[k] = 2\n",
    "\n",
    "        best_hp_dict['max_depth'] = list(set([\n",
    "            int(x) for x in range(\n",
    "                dict_max_depth - math.ceil(dict_max_depth / 10),\n",
    "                dict_max_depth + math.ceil(dict_max_depth / 10) + 1,\n",
    "                5)\n",
    "        ]))\n",
    "\n",
    "        if dict_max_features == 'sqrt':\n",
    "            best_hp_dict['max_features'] = [math.floor(math.sqrt(self.data.shape[1])),\n",
    "                                            math.ceil(math.sqrt(self.data.shape[1]))]\n",
    "        else:\n",
    "            best_hp_dict['max_features'] = [math.floor(math.log2(self.data.shape[1])),\n",
    "                                            math.ceil(math.log2(self.data.shape[1]))]\n",
    "\n",
    "        RF_test_random_Grid = GridSearchCV(estimator=RF_test_base,\n",
    "                                           param_grid=best_hp_dict,\n",
    "                                           cv=KFold(n_splits=self.cv, shuffle=True,\n",
    "                                                    random_state=self.seed),\n",
    "                                           scoring=self.scoring,\n",
    "                                           refit='neg_mse',\n",
    "                                           n_jobs=self.NJobs\n",
    "                                          )\n",
    "        \n",
    "        best_hp_dict['ccp_alpha'] = [dict_ccp_alpha]\n",
    "\n",
    "        RF_test_random_Grid.fit(self.X_train, self.y_train)\n",
    "        self.best_RF_model = RF_test_random_Grid.best_estimator_\n",
    "        self.y_pred = RF_test_random_Grid.predict(self.X_test)\n",
    "\n",
    "        return self.best_RF_model, self.y_pred\n",
    "\n",
    "    def Evaluating(self):\n",
    "        RF_R2 = r2_score(self.y_test, self.y_pred)\n",
    "        RF_RMSE = mean_squared_error(self.y_test, self.y_pred) ** 0.5\n",
    "        RF_MAE = mean_absolute_error(self.y_test, self.y_pred)\n",
    "        print('R_Squared is {:.3f}, RMSE is {:.3f}, MAE is {:.3f}'.format(RF_R2, RF_RMSE, RF_MAE))\n",
    "\n",
    "    def plot_RF_pred(self):\n",
    "        plt.scatter(self.y_pred, self.y_test, alpha=0.6)\n",
    "        w = np.linspace(min(self.y_pred), max(self.y_pred), 100)\n",
    "        plt.plot(w, w)\n",
    "        plt.xlabel('y_pred')\n",
    "        plt.ylabel('y_test')\n",
    "        plt.title('Random Forest Prediction')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_Feature_Importance(self, RF_Feature_Importance_path=None):\n",
    "        # 绘制变量重要性柱状图\n",
    "        sorted_index = self.best_RF_model.feature_importances_.argsort()\n",
    "        a = plt.barh(\n",
    "            range(self.data.shape[1]),\n",
    "            np.around(self.best_RF_model.feature_importances_[sorted_index], 3),\n",
    "            color='darkgray'\n",
    "        )\n",
    "        plt.bar_label(a, label_type='edge')\n",
    "        plt.yticks(np.arange(self.data.shape[1]), self.data.columns[sorted_index])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if RF_Feature_Importance_path is None:\n",
    "            plt.show()\n",
    "        if RF_Feature_Importance_path is not None:\n",
    "            plt.savefig(RF_Feature_Importance_path)\n",
    "\n",
    "    def plot_PDP(self, pdp_features, perc=(0.05, 0.95), RF_PDP_path=None):\n",
    "        # PDP图\n",
    "        PDP = PartialDependenceDisplay.from_estimator(\n",
    "            self.best_RF_model,\n",
    "            self.X_train,\n",
    "            percentiles=perc,\n",
    "            features=[pdp_features],\n",
    "            kind='average',\n",
    "            line_kw={\"color\": \"darkgray\", 'linewidth':3.0},\n",
    "            n_jobs=self.NJobs\n",
    "        )\n",
    "        plt.title(f'PDP for {self.best_RF_model.__class__.__name__}')\n",
    "        \n",
    "        #x、y轴标签字体大小\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.xticks(fontsize=12)\n",
    "        \n",
    "        #x、y轴标题字体大小\n",
    "        plt.xlabel(\"The level of the city's digital economy\", fontsize=12)\n",
    "        plt.ylabel('Partial dependence', fontsize=12)\n",
    "        \n",
    "        # 删除图片边框\n",
    "        ax=plt.gca()\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        if RF_PDP_path is None:\n",
    "            plt.show()\n",
    "        if RF_PDP_path is not None:\n",
    "            plt.savefig(RF_PDP_path, dpi=350, bbox_inches='tight')\n",
    "\n",
    "    def plot_Both(self, both_features, RF_Both_path=None):\n",
    "        # 绘制PDP & ICE 组合图\n",
    "        PartialDependenceDisplay.from_estimator(self.best_RF_model,\n",
    "                                                self.X_train,\n",
    "                                                features=[both_features],\n",
    "                                                kind='both',\n",
    "                                                ice_lines_kw={\"color\": \"darkgray\"},\n",
    "                                                pd_line_kw={\"color\": \"k\"},\n",
    "                                                n_jobs=self.NJobs\n",
    "                                                )\n",
    "#         plt.title(f'PDP & ICE for {self.best_RF_model.__class__.__name__}')\n",
    "        # 删除图片边框\n",
    "        ax=plt.gca()\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        #x、y轴标签字体大小\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        \n",
    "        if RF_Both_path is None:\n",
    "            plt.show()\n",
    "        if RF_Both_path is not None:\n",
    "            plt.savefig(RF_Both_path, dpi=500)\n",
    "            \n",
    "    def plot_ale(self, feat, have_CI=False, ale_path=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        ale_eff = ale(X=self.data, model=self.best_RF_model,\n",
    "                      feature=[feat], feature_type=\"continuous\",\n",
    "                      fig=fig, ax=ax,\n",
    "                      grid_size=500, include_CI=have_CI)\n",
    "        \n",
    "        line = ax.get_lines()\n",
    "        line[0].set_color('darkgray')\n",
    "        line[0].set_linewidth(3)\n",
    "        \n",
    "        ax.set_title(\"\")\n",
    "        # 删除图片边框\n",
    "        ax=plt.gca()\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        #x、y轴标签字体大小\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        \n",
    "        if ale_path is None:\n",
    "            plt.show()\n",
    "        if ale_path is not None:\n",
    "            plt.savefig(ale_path, dpi=1000, bbox_inches='tight')\n",
    "            \n",
    "    def plot_3d_pd(self,\n",
    "                   features1, features2,\n",
    "                   surface_cmap=plt.get_cmap(\"Greys\"),\n",
    "                   suptitle=None, sup_fontsize=15,\n",
    "                   view_elev=45, view_azim=45,\n",
    "                   colorbar_pad=0.08, colorbar_shrink=0.6, colorbar_aspect=10,\n",
    "                   three_pd_path=None\n",
    "                   ):\n",
    "        fig = plt.figure()\n",
    "        # 3D偏效应图\n",
    "        features = [features1, features2]\n",
    "        pdp = partial_dependence(\n",
    "            self.best_RF_model,\n",
    "            self.X_train,\n",
    "            features=features,\n",
    "            kind=\"average\",\n",
    "            grid_resolution=10\n",
    "        )\n",
    "        XX, YY = np.meshgrid(pdp[\"values\"][0], pdp[\"values\"][1])\n",
    "        Z = pdp.average[0].T\n",
    "        ax = fig.add_subplot(projection=\"3d\")\n",
    "        fig.add_axes(ax)\n",
    "        surf = ax.plot_surface(XX, YY, Z, rstride=1, cstride=1, cmap=surface_cmap, edgecolor=\"w\")\n",
    "        \n",
    "        # x、y、z轴标签字体大小\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.xticks(fontsize=12)\n",
    "        ax.tick_params(axis='z',labelsize=12)\n",
    "        \n",
    "        # 标签字体大小\n",
    "        ax.set_xlabel(features[0], fontsize=12)\n",
    "        ax.set_ylabel(features[1], fontsize=12)\n",
    "        ax.zaxis.set_rotate_label(False)  #一定要先关掉默认的旋转设置\n",
    "        ax.set_zlabel(\"GMLPI\", fontsize=12, rotation = 90)\n",
    "        \n",
    "        fig.suptitle(\n",
    "            suptitle,\n",
    "            fontsize=sup_fontsize,\n",
    "        )\n",
    "        ax.view_init(elev=view_elev, azim=view_azim)  # 3d视角\n",
    "        clb = plt.colorbar(surf, pad=colorbar_pad,\n",
    "                           shrink=colorbar_shrink,\n",
    "                           aspect=colorbar_aspect)\n",
    "        clb.ax.set_title(\"Partial\\ndependence\")\n",
    "        \n",
    "        if three_pd_path is None:\n",
    "            plt.show()\n",
    "        if three_pd_path is not None:\n",
    "            plt.savefig(three_pd_path, dpi=600)\n",
    "\n",
    "    def plot_child_tree(self,\n",
    "                        child_numb,\n",
    "                        tree_graph_dot_path=None,\n",
    "                        tree_graph_png_path=None):\n",
    "\n",
    "        # 随机森林其中一颗决策树-可视化\n",
    "        RF_child_tree = self.best_RF_model[child_numb]\n",
    "        export_graphviz(RF_child_tree, out_file=tree_graph_dot_path,\n",
    "                        feature_names=self.data.columns, rounded=True, precision=3)\n",
    "\n",
    "        if tree_graph_dot_path is not None and tree_graph_png_path is not None:\n",
    "            random_forest_graph = pydotplus.graph_from_dot_file(tree_graph_dot_path)\n",
    "            random_forest_graph.write_png(tree_graph_png_path)\n",
    "\n",
    "    def plot_learning_curve(self, data, target,\n",
    "                            test_line_marker=\"^\", test_line_color=\"k\",\n",
    "                            scoring=\"neg_mean_squared_error\",\n",
    "                            score_name=\"mean_squared_error\",\n",
    "                            train_line_linestyle='dotted', train_line_marker=\"s\",\n",
    "                            learning_curve_path=None\n",
    "                            ):\n",
    "        # 绘制学习曲线图\n",
    "        _, ax = plt.subplots()\n",
    "        X = data\n",
    "        y = target\n",
    "        common_params = {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "            \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=self.seed),\n",
    "            \"scoring\": scoring,\n",
    "            \"negate_score\": True,\n",
    "            \"score_type\": \"both\",\n",
    "            \"n_jobs\": self.NJobs,\n",
    "            \"line_kw\": {\"marker\": test_line_marker, \"color\": test_line_color, 'linewidth':3.0},\n",
    "            \"fill_between_kw\": {\"color\": \"lightgray\"},\n",
    "            \"std_display_style\": \"fill_between\",\n",
    "            \"score_name\": score_name,\n",
    "        }\n",
    "\n",
    "        LearningCurveDisplay.from_estimator(estimator=self.best_RF_model, **common_params, ax=ax)\n",
    "        line1, line2 = ax.get_lines()\n",
    "        line1.set_linestyle(train_line_linestyle)\n",
    "        line1.set_marker(train_line_marker)\n",
    "        handles, label = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "#         plt.title(f\"Learning Curve for {self.best_RF_model.__class__.__name__}\")\n",
    "\n",
    "        # x、y轴标签字体大小\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.xticks(fontsize=10)\n",
    "        \n",
    "        # 轴标题字体大小\n",
    "        plt.xlabel(\"Training set size\", fontsize=10)\n",
    "        plt.ylabel(\"Mean square error\", fontsize=10)\n",
    "#         plt.ylabel(f\"Score: {score_name}\", fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 删除图片边框\n",
    "        ax=plt.gca()\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        \n",
    "        if learning_curve_path is None:\n",
    "            plt.show()\n",
    "        if learning_curve_path is not None:\n",
    "            plt.savefig(learning_curve_path, dpi=300)\n",
    "\n",
    "    def plot_permutation_importance(self, permutation_importance_path=None):\n",
    "        result = permutation_importance(self.best_RF_model, self.X_train, self.y_train,\n",
    "                                        n_repeats=10,\n",
    "                                        random_state=self.seed,\n",
    "                                        n_jobs=self.NJobs\n",
    "                                        )\n",
    "        sorted_idx = result.importances_mean.argsort()\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.boxplot(result.importances[sorted_idx].T,\n",
    "                   vert=False,\n",
    "                   patch_artist=False,\n",
    "                   medianprops=dict(color=\"k\"),\n",
    "                   labels=self.X_train.columns[sorted_idx]\n",
    "                   )\n",
    "        ax.set_title(\"Permutation Importances\")\n",
    "        plt.xlabel(\"Importances\"), plt.ylabel(\"Variables\")\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        if permutation_importance_path is None:\n",
    "            plt.show()\n",
    "        if permutation_importance_path is not None:\n",
    "            plt.savefig(permutation_importance_path, dpi=300)\n",
    "\n",
    "    def plot_feature_shap(self, feature_shap_path=None):\n",
    "        \n",
    "        shap_values = shap.TreeExplainer(self.best_RF_model).shap_values(self.X_train)\n",
    "        shap_v = pd.DataFrame(shap_values)\n",
    "        feature_lst = self.X_train.columns\n",
    "        shap_v.columns = feature_lst\n",
    "        df_v = self.X_train.copy().reset_index().drop('index', axis=1)\n",
    "\n",
    "        # 求SHAP值与data的相关系数，判断正负影响\n",
    "        corr_lst = list()\n",
    "        for i in feature_lst:\n",
    "            b = np.corrcoef(shap_v[i], df_v[i])[1][0]\n",
    "            corr_lst.append(b)\n",
    "        corr_df = pd.concat([pd.Series(feature_lst), pd.Series(corr_lst)], axis=1).fillna(0)\n",
    "        corr_df.columns = ['Variable', 'Corr']\n",
    "        corr_df['Sign'] = np.where(corr_df['Corr'] > 0, '//', '')\n",
    "\n",
    "        # Plot\n",
    "        shap_abs = np.abs(shap_v)\n",
    "        k = pd.DataFrame(shap_abs.mean()).reset_index()\n",
    "        k.columns = ['Variable', 'SHAP_abs']\n",
    "        k2_ = k.merge(corr_df, left_on='Variable', right_on='Variable', how='inner')\n",
    "        k2_ = k2_.sort_values(by='SHAP_abs', ascending=True)\n",
    "        k2 = np.around(k2_, 4)\n",
    "        k3 = k2.copy()\n",
    "        k3.loc[k3['Sign'] == '//', 'SHAP_abs'] = np.nan  # k3仅包含负shap值\n",
    "        k4 = k2.copy()\n",
    "        k4.loc[k4['Sign'] == '', 'SHAP_abs'] = np.nan  # k4仅包含正shap值\n",
    "        k3['SHAP_abs'] = -k3['SHAP_abs']\n",
    "        hatch_lst = k2['Sign']\n",
    "        k4.plot.barh(x='Variable', y='SHAP_abs',\n",
    "                     color='w', edgecolor=\"k\", width=0.75,\n",
    "                     hatch=hatch_lst, legend=False)\n",
    "        plt.barh(k3['Variable'], k3['SHAP_abs'], color='w', edgecolor=\"k\", hatch=hatch_lst)\n",
    "        \n",
    "#         plt.title(\"Shapley Additive Explanations\")\n",
    "            \n",
    "        #x、y轴标签字体大小\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.xticks(fontsize=10)\n",
    "        \n",
    "        #x、y轴标题字体大小\n",
    "        plt.xlabel(\"corr × mean(|Shapley values|)\", fontsize=10)\n",
    "        plt.ylabel('Explanatory variables', fontsize=10)\n",
    "        \n",
    "        # 删除图片边框\n",
    "        ax=plt.gca()\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        # x轴保留4位小数\n",
    "        ax.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.4f'))\n",
    "        \n",
    "        if feature_shap_path is None:\n",
    "            plt.show()\n",
    "        if feature_shap_path is not None:\n",
    "            plt.gcf().subplots_adjust(left=0.2,top=0.91,bottom=0.09)\n",
    "            plt.savefig(feature_shap_path, dpi=500, bbox_inches='tight')\n",
    "\n",
    "    def plot_interaction_dependence(self, main_var, other_var, interaction_dependence_path=None):\n",
    "        cols = [i for i in self.data.columns]\n",
    "        shap_values = shap.TreeExplainer(self.best_RF_model).shap_values(self.data)\n",
    "        shap.dependence_plot(main_var,\n",
    "                             shap_values,\n",
    "                             self.data[cols],\n",
    "                             interaction_index=other_var,\n",
    "                             cmap=plt.get_cmap(\"tab20c\")\n",
    "                             )\n",
    "        if interaction_dependence_path is None:\n",
    "            plt.show()\n",
    "        if interaction_dependence_path is not None:\n",
    "            plt.savefig(interaction_dependence_path, dpi=500)\n",
    "\n",
    "\n",
    "class Bagging_Regression_Model(RF_Regression_Model):\n",
    "\n",
    "    def __init__(self, XTrain, yTrain, XTest, yTest, data):\n",
    "        super().__init__(XTrain, yTrain, XTest, yTest, data)  # 继承父类属性\n",
    "        self.__Bagging_max_samples = list(round(float(x), 2) for x in np.linspace(0.5, 1, 5))\n",
    "        self.__Bagging_max_features_range = list(range(1, self.data.shape[1] + 1))\n",
    "\n",
    "    # Baggging 无法计算变量重要性并排序\n",
    "    plot_Feature_Importance = None\n",
    "    # Bagging 无法计算SHAP值\n",
    "    plot_feature_shap = None\n",
    "\n",
    "    def search_hp_fit(self):\n",
    "        # 随机搜索选取最优超参数-RandomSearch\n",
    "        Bagging_hp_range = {'n_estimators': self.n_estimators_range,\n",
    "                            'max_features': self.__Bagging_max_features_range,\n",
    "                            'max_samples': self.__Bagging_max_samples\n",
    "                            }\n",
    "\n",
    "        # 测试基回归器Bagging\n",
    "        Bagging_test_base = BaggingRegressor(oob_score=False,\n",
    "                                             bootstrap=True,\n",
    "                                             random_state=self.seed,\n",
    "                                             n_jobs=self.NJobs\n",
    "                                             )\n",
    "\n",
    "        Bagging_test_random = RandomizedSearchCV(estimator=Bagging_test_base,\n",
    "                                                 param_distributions=Bagging_hp_range,\n",
    "                                                 n_iter=200,\n",
    "                                                 n_jobs=self.NJobs,\n",
    "                                                 cv=KFold(n_splits=self.cv, shuffle=True, random_state=self.seed),\n",
    "                                                 random_state=self.seed,\n",
    "                                                 scoring=self.scoring,\n",
    "                                                 refit='neg_mse'\n",
    "                                                 )\n",
    "\n",
    "        Bagging_test_random.fit(self.X_train, self.y_train)\n",
    "\n",
    "        Bagging_best_hp_Random = Bagging_test_random.best_params_\n",
    "        Bagging_best_hp_dict = Bagging_best_hp_Random\n",
    "\n",
    "        # GridSearchCV精准搜索寻找最优超参数：缩小超参数范围，确定最优超参数\n",
    "        Bagging_dict_n_estimators = Bagging_best_hp_dict['n_estimators']\n",
    "        Bagging_dict_max_samples = Bagging_best_hp_dict['max_samples']\n",
    "\n",
    "        Bagging_best_hp_dict['n_estimators'] = [\n",
    "            int(x) for x in range(Bagging_dict_n_estimators - math.ceil(Bagging_dict_n_estimators / 10),\n",
    "                                  Bagging_dict_n_estimators + math.ceil(Bagging_dict_n_estimators / 10),\n",
    "                                  10)\n",
    "        ]\n",
    "\n",
    "        Bagging_best_hp_dict['max_features'] = [math.floor(math.sqrt(self.data.shape[1])),\n",
    "                                                math.ceil(math.sqrt(self.data.shape[1]))]\n",
    "\n",
    "        Bagging_best_hp_dict['max_samples'] = [round(float(x), 3) for x in np.linspace(Bagging_dict_max_samples + 0.1,\n",
    "                                                                                       Bagging_dict_max_samples - 0.1,\n",
    "                                                                                       5)\n",
    "                                               ]\n",
    "        # max_samples 小于等于1\n",
    "        for k in range(0, len(Bagging_best_hp_dict.get('max_samples'))):\n",
    "            if Bagging_best_hp_dict.get('max_samples')[k] > 1:\n",
    "                Bagging_best_hp_dict.get('max_samples')[k] = 1\n",
    "\n",
    "        Bagging_test_random_Grid = GridSearchCV(estimator=Bagging_test_base,\n",
    "                                                param_grid=Bagging_best_hp_dict,\n",
    "                                                cv=KFold(n_splits=self.cv, shuffle=True, random_state=self.seed),\n",
    "                                                scoring=self.scoring,\n",
    "                                                n_jobs=self.NJobs,\n",
    "                                                refit='neg_mse'\n",
    "                                                )\n",
    "\n",
    "        Bagging_test_random_Grid.fit(self.X_train, self.y_train)\n",
    "        self.best_RF_model = Bagging_test_random_Grid.best_estimator_\n",
    "        self.y_pred = Bagging_test_random_Grid.predict(self.X_test)\n",
    "\n",
    "        return self.best_RF_model, self.y_pred\n",
    "\n",
    "\n",
    "class GBDT_Regression_Model(RF_Regression_Model):\n",
    "\n",
    "    def __init__(self, XTrain, yTrain, XTest, yTest, data):\n",
    "        super().__init__(XTrain, yTrain, XTest, yTest, data)  # 继承父类属性\n",
    "        self.__Boosting_max_depth_range = [int(x) for x in np.linspace(0, 20, num=10)]\n",
    "        self.__Boosting_min_samples_split_range = [1, 2, 5, 10]\n",
    "        self.__Boosting_min_samples_leaf_range = [1, 2, 4, 8]\n",
    "        self.__sub_sample = [round(float(x), 3) for x in np.linspace(0.5, 1, 5)]\n",
    "        self.__learning_rate = [round(float(x), 3) for x in np.linspace(0.01, 0.2, 5)]\n",
    "        self.__alpha = [round(float(x), 3) for x in np.linspace(0.8, 0.99, 5)]\n",
    "        self.__loss_fuc = 'huber'\n",
    "\n",
    "    plot_child_tree = None\n",
    "\n",
    "    def search_hp_fit(self):\n",
    "        Boosting_hp_range = {'n_estimators': self.n_estimators_range,\n",
    "                             'max_depth': self.__Boosting_max_depth_range,\n",
    "                             'min_samples_split': self.__Boosting_min_samples_split_range,\n",
    "                             'min_samples_leaf': self.__Boosting_min_samples_leaf_range,\n",
    "                             'subsample': self.__sub_sample,\n",
    "                             'learning_rate': self.__learning_rate,\n",
    "                             'alpha': self.__alpha\n",
    "                             }\n",
    "\n",
    "        GBDT_test_base = GradientBoostingRegressor(loss=self.__loss_fuc,\n",
    "                                                   # 提前停止防止过拟合\n",
    "                                                   # validation_fraction=0.1,\n",
    "                                                   # n_iter_no_change=5, tol=0.01,\n",
    "                                                   random_state=self.seed)\n",
    "\n",
    "        GBDT_test_random = RandomizedSearchCV(estimator=GBDT_test_base,\n",
    "                                              param_distributions=Boosting_hp_range,\n",
    "                                              n_iter=200,\n",
    "                                              n_jobs=self.NJobs,\n",
    "                                              cv=KFold(n_splits=self.cv, shuffle=True, random_state=self.seed),\n",
    "                                              random_state=self.seed,\n",
    "                                              refit='neg_mse',\n",
    "                                              scoring=self.scoring\n",
    "                                              )\n",
    "\n",
    "        GBDT_test_random.fit(self.X_train, self.y_train)\n",
    "        GBDT_best_hp_Random = GBDT_test_random.best_params_\n",
    "        GBDT_best_hp_dict = GBDT_best_hp_Random\n",
    "\n",
    "        # GridSearchCV精准搜索寻找最优超参数：缩小超参数范围，确定最优超参数\n",
    "        GBDT_dict_n_estimators = GBDT_best_hp_dict['n_estimators']\n",
    "        GBDT_min_samples_split = GBDT_best_hp_dict['min_samples_split']\n",
    "        GBDT_dict_min_samples_leaf = GBDT_best_hp_dict['min_samples_leaf']\n",
    "        GBDT_dict_max_depth = GBDT_best_hp_dict['max_depth']\n",
    "        GBDT_dict_subsample = GBDT_best_hp_dict['subsample']\n",
    "        GBDT_dict_learning_rate = GBDT_best_hp_dict['learning_rate']\n",
    "        GBDT_dict_alpha = GBDT_best_hp_dict['alpha']\n",
    "\n",
    "        GBDT_best_hp_dict['n_estimators'] = [GBDT_dict_n_estimators]\n",
    "        GBDT_best_hp_dict['min_samples_split'] = [GBDT_min_samples_split]\n",
    "        GBDT_best_hp_dict['min_samples_leaf'] = [GBDT_dict_min_samples_leaf]\n",
    "        GBDT_best_hp_dict['max_depth'] = [GBDT_dict_max_depth]\n",
    "\n",
    "        GBDT_best_hp_dict['subsample'] = [\n",
    "            round(float(x), 3) for x in np.linspace(GBDT_dict_subsample - 0.1, GBDT_dict_subsample + 0.1, 5)\n",
    "        ]\n",
    "\n",
    "        # subsample 必须在区间（0,1）内\n",
    "        for i in range(0, len(GBDT_best_hp_dict.get('subsample'))):\n",
    "            if GBDT_best_hp_dict.get('subsample')[i] <= 0:\n",
    "                GBDT_best_hp_dict.get('subsample')[i] = 0.5\n",
    "\n",
    "            if GBDT_best_hp_dict.get('subsample')[i] >= 1:\n",
    "                GBDT_best_hp_dict.get('subsample')[i] = 1\n",
    "\n",
    "        GBDT_best_hp_dict['learning_rate'] = [\n",
    "            round(float(x), 3) for x in np.linspace(\n",
    "                GBDT_dict_learning_rate - 0.1, GBDT_dict_learning_rate + 0.1, 5\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # learning_rate 必须在区间（0,1）内\n",
    "        for i in range(0, len(GBDT_best_hp_dict.get('learning_rate'))):\n",
    "            if GBDT_best_hp_dict.get('learning_rate')[i] <= 0:\n",
    "                GBDT_best_hp_dict.get('learning_rate')[i] = 0.01\n",
    "\n",
    "            if GBDT_best_hp_dict.get('learning_rate')[i] >= 1:\n",
    "                GBDT_best_hp_dict.get('learning_rate')[i] = 0.2\n",
    "\n",
    "        GBDT_best_hp_dict['alpha'] = [\n",
    "            round(float(x), 3) for x in np.linspace(\n",
    "                GBDT_dict_alpha - 0.1, GBDT_dict_alpha + 0.1, 5\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # alpha 必须在区间（0,1）内\n",
    "        for i in range(0, len(GBDT_best_hp_dict.get('alpha'))):\n",
    "            if GBDT_best_hp_dict.get('alpha')[i] <= 0:\n",
    "                GBDT_best_hp_dict.get('alpha')[i] = 0.8\n",
    "\n",
    "            if GBDT_best_hp_dict.get('alpha')[i] >= 1:\n",
    "                GBDT_best_hp_dict.get('alpha')[i] = 0.99\n",
    "\n",
    "        GBDT_test_random_Grid = GridSearchCV(estimator=GBDT_test_base,\n",
    "                                             param_grid=GBDT_best_hp_dict,\n",
    "                                             cv=KFold(n_splits=self.cv, shuffle=True, random_state=self.seed),\n",
    "                                             scoring=self.scoring,\n",
    "                                             n_jobs=self.NJobs,\n",
    "                                             refit='neg_mse'\n",
    "                                             )\n",
    "\n",
    "        GBDT_test_random_Grid.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # 使用最优超参数拟合模型\n",
    "        self.best_RF_model = GBDT_test_random_Grid.best_estimator_\n",
    "        self.y_pred = GBDT_test_random_Grid.predict(self.X_test)\n",
    "\n",
    "        return self.best_RF_model, self.y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bd5ba-cd88-4c57-8e4d-e10ec9067024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
